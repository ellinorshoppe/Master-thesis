{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "486396a7",
   "metadata": {},
   "source": [
    "# Evaluation of models on corrected and non-corrected top1 molecular formula prediction fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077d0e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category = RuntimeWarning)\n",
    "warnings.filterwarnings('ignore', category = UserWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "import pickle\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515b6d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for making predictions\n",
    "def MonteCarlo_prediction(fp, model, n_samples=10000):\n",
    "    binary_samples = np.random.binomial(1, fp, size=(n_samples, len(fp)))\n",
    "    predicted_probabilities = model.predict_proba(binary_samples)[:, 1]\n",
    "    return np.mean(predicted_probabilities)\n",
    "\n",
    "def make_predictions(data, model):\n",
    "    df = data[np.concatenate([['id', 'formula'], model.feature_names_in_])]\n",
    "    predicted_probabilities =  df[model.feature_names_in_].apply(lambda x: MonteCarlo_prediction(np.array(x), model=model), axis=1)\n",
    "    return predicted_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87b6bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "\n",
    "ahr_rf_model = pickle.load(open('/Users/elli/Library/CloudStorage/OneDrive-Kruvelab/Master_thesis/Code/Model_training/AHR/RF/2025-05-14_RF_feat_var_0.9_ahr_CORRECT_FINAL_correct_features.pkl', 'rb'))\n",
    "ahr_xgb_model = pickle.load(open('/Users/elli/Library/CloudStorage/OneDrive-Kruvelab/Master_thesis/Code/Model_training/AHR/XGBoost/2025-05-14_XGBoost_feat_var_0.9_ahr_CORRECT_FINAL_correct_features.pkl', 'rb'))\n",
    "\n",
    "mmp_rf_model = pickle.load(open('/Users/elli/Library/CloudStorage/OneDrive-Kruvelab/Master_thesis/Code/Model_training/MMP/RF/2025-05-14_RF_feat_var_0.9_mmp_CORRECT_FINAL_correct_features.pkl','rb'))\n",
    "mmp_xgb_model = pickle.load(open('/Users/elli/Library/CloudStorage/OneDrive-Kruvelab/Master_thesis/Code/Model_training/MMP/XGBoost/2025-05-14_XGBoost_feat_var_0.9_mmp_CORRECT_FINAL_correct_features.pkl','rb'))\n",
    "\n",
    "#Load feature names\n",
    "ahr_features = pickle.load(open('/Users/elli/Library/CloudStorage/OneDrive-Kruvelab/Master_thesis/Code/Model_training/AHR/ahr_features.pkl','rb'))\n",
    "mmp_features = pickle.load(open('/Users/elli/Library/CloudStorage/OneDrive-Kruvelab/Master_thesis/Code/Model_training/MMP/mmp_features.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73f62ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4d54c4a",
   "metadata": {},
   "source": [
    "# Prediction of top 1 formula fingerprints WITHOUT mass correction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fe2d89",
   "metadata": {},
   "source": [
    "## Get all fingerprints for top 1 molecular formula\n",
    "\n",
    "Code by Ida Rahu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0980605f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ellinor = '/Users/elli/Library/CloudStorage/OneDrive-Kruvelab/Master_thesis/Data/MSMS/SIRIUS_output/output_no_mass_correction/ellinor_data'\n",
    "iris = '/Users/elli/Library/CloudStorage/OneDrive-Kruvelab/Master_thesis/Data/MSMS/SIRIUS_output/output_no_mass_correction/iris_data_dry'\n",
    "isabell = '/Users/elli/Library/CloudStorage/OneDrive-Kruvelab/Master_thesis/Data/MSMS/SIRIUS_output/output_no_mass_correction/isabell_data'\n",
    "library = '/Users/elli/Library/CloudStorage/OneDrive-Kruvelab/Master_thesis/Data/MSMS/SIRIUS_output/output_no_mass_correction/library_data'\n",
    "\n",
    "output_folders = [ellinor, iris, isabell, library]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1a1e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rank1_fingerprints(output_folders, esi_mode='pos'):\n",
    "    sirius_output_folder = ellinor # Folder with SIRIUS+CSI:FingerID results\n",
    "\n",
    "    if esi_mode == 'pos':\n",
    "        fp_info = pd.read_csv(f'{sirius_output_folder}/csi_fingerid.tsv', sep='\\t')\n",
    "    else:\n",
    "        fp_info = pd.read_csv(f'{sirius_output_folder}/csi_fingerid_neg.tsv', sep='\\t')\n",
    "\n",
    "    # Generating the dataframe for SIRIUS+CSI:FingerID results\n",
    "    columns = np.concatenate([['id', 'formula', 'adduct'], [idx for idx in fp_info.relativeIndex.values]], axis=0)\n",
    "    fp_data = pd.DataFrame(columns=columns)\n",
    "\n",
    "    without_fp = [] # Array for MS features without predicted fingerprints\n",
    "\n",
    "    for output_folder in output_folders:\n",
    "        for file_name in glob.glob(f'{sirius_output_folder}/*/formula_candidates.tsv'):\n",
    "            data = pd.read_csv(file_name, sep='\\t')\n",
    "            rank1formula = data[data.formulaRank == 1].molecularFormula.values[0]\n",
    "            adduct = data[data.formulaRank == 1].adduct.values[0].replace(' ', '') # Using fingerprints of rank 1 formulas\n",
    "            id = os.path.basename(os.path.dirname(file_name)).split('_')[1:]\n",
    "            id = '_'.join(id[:len(id)//2])\n",
    "            try:\n",
    "                fp = pd.read_csv(f'{os.path.dirname(file_name)}/fingerprints/{rank1formula}_{adduct}.fpt', header=None).T.values.flatten()\n",
    "                data_ready = np.concatenate([[id, rank1formula, adduct], fp], axis=0)\n",
    "                fp_data.loc[len(fp_data)] = data_ready\n",
    "            except:\n",
    "                without_fp.append(id)\n",
    "\n",
    "    fp_data = fp_data.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "    fp_data.columns = [int(col) if col.isnumeric() else col for col in fp_data.columns]\n",
    "\n",
    "    return fp_data, without_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed3fe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_data_non_corrected, without_fp = get_rank1_fingerprints(output_folders, esi_mode='pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658a16f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_data_non_corrected.sort_values(by=['id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc28983",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_data_non_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76812f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_data_non_corrected=fp_data_non_corrected.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422dab02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for making predictions\n",
    "def MonteCarlo_prediction(fp, model, n_samples=10000):\n",
    "    binary_samples = np.random.binomial(1, fp, size=(n_samples, len(fp)))\n",
    "    predicted_probabilities = model.predict_proba(binary_samples)[:, 1]\n",
    "    return np.mean(predicted_probabilities)\n",
    "\n",
    "def make_predictions(data, model, feature_names):\n",
    "    df = data.iloc[:, list(feature_names)]\n",
    "    predicted_probabilities =  df.apply(lambda x: MonteCarlo_prediction(np.array(x), model=model), axis=1)\n",
    "    return predicted_probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7036f6",
   "metadata": {},
   "source": [
    "## Make model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c719f991",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [ahr_rf_model, ahr_xgb_model, mmp_rf_model, mmp_xgb_model]\n",
    "model_name = ['ahr_rf_pred', 'ahr_xgb_pred', 'mmp_rf_pred', 'mmp_xgb_pred']\n",
    "\n",
    "predicted_results_uncorrected = fp_data_non_corrected[['id', 'formula', 'adduct']].copy()\n",
    "\n",
    "for model, name in zip(models, model_name): \n",
    "    if model == ahr_rf_model or model == ahr_xgb_model:\n",
    "        feature_names = ahr_features\n",
    "    else:\n",
    "        feature_names = mmp_features\n",
    "\n",
    "    # Make predictions\n",
    "    predicted_probabilities = make_predictions(fp_data_non_corrected.iloc[:, 3:], model, feature_names)\n",
    "    \n",
    "    # Add the predicted probabilities to the dataframe\n",
    "    predicted_results_uncorrected[name] = predicted_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc252bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_results_uncorrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75cdea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('2025-05-21_Model_evaluation_top1MF_pred_uncorrected_mass.pkl', 'wb') as f:\n",
    "#     pickle.dump(predicted_results_uncorrected, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90da6c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('/Users/elli/Library/CloudStorage/OneDrive-Kruvelab/Master_thesis/Data/MSMS/SIRIUS_output/output_no_mass_correction/2025-05-21_Rank1_fingerprints.pkl', 'wb') as f:\n",
    "#     pickle.dump(fp_data_non_corrected, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b6f885",
   "metadata": {},
   "source": [
    "## Get the corresponding label to the names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3758d76f",
   "metadata": {},
   "source": [
    "### Clean names in the 'id' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabc3408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b8d0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('2025-05-21_Model_evaluation_top1MF_pred_uncorrected_mass.pkl', 'rb') as f:\n",
    "    predicted_results_uncorrected = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13df248d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_results_uncorrected.id = predicted_results_uncorrected.id.apply(lambda x: x.translate(str.maketrans('', '', '()[]{}<>,.+ :\\'\\\"'))).str.lower()\n",
    "\n",
    "predicted_results_uncorrected.id = predicted_results_uncorrected.id.apply(lambda x: x.split('_'))\n",
    "\n",
    "predicted_results_uncorrected.id = [x[0:-1] if x[-1]=='combined'\n",
    "                            else x for x in predicted_results_uncorrected.id]\n",
    "\n",
    "predicted_results_uncorrected.id = ['_'.join(x[0:-1]) if x[-1]=='e' or x[-1]=='h' or x[-1].isnumeric()\n",
    "                            else '_'.join(x) for x in predicted_results_uncorrected.id]\n",
    "\n",
    "predicted_results_uncorrected.id = predicted_results_uncorrected.id.apply(lambda x: x.translate(str.maketrans('', '', '_-')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072b6129",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_results_uncorrected.sort_values(by=['id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1ea063",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_results_uncorrected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579e0b9a",
   "metadata": {},
   "source": [
    "### clean the ID column in 'ground truth' and merge with tox21 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913782a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/elli/Library/CloudStorage/OneDrive-Kruvelab/Master_thesis/Data/MSMS/SIRIUS_output/2025-05-13_ground_truth_molecular_formula_no_sirius.pkl', 'rb') as f:\n",
    "     ground_truth = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f23a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth.id = ground_truth.id.apply(lambda x: x.translate(str.maketrans('', '', '_-')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56fa8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1cedd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/elli/Library/CloudStorage/OneDrive-Kruvelab/Master_thesis/Code/Tox21 comparison/2025-03-06_tox21_ahr_mmp_available_compounds_all_sources_UPDATED.pkl','rb') as f:\n",
    "    tox21 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a11b5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tox21 = tox21.drop_duplicates(subset='InChIKey14', keep='first')\n",
    "tox21 = tox21[tox21.sirius_data.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fa0e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "tox21_gt = tox21.merge(ground_truth[['InChIKey14', 'id', 'molecular_formula']], how='left', on='InChIKey14')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1ed438",
   "metadata": {},
   "outputs": [],
   "source": [
    "tox21_gt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ae45dd",
   "metadata": {},
   "source": [
    "### Merge the fp data with ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d4c790",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_data_uncorrected_with_gt = tox21_gt.merge(predicted_results_uncorrected, on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6b3c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_data_uncorrected_with_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e068e769",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_data_uncorrected_with_gt = fp_data_uncorrected_with_gt.drop_duplicates(subset=fp_data_uncorrected_with_gt.columns, keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed97af79",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_data_uncorrected_with_gt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a21678",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_data_uncorrected_with_gt_final = fp_data_uncorrected_with_gt[fp_data_uncorrected_with_gt.formula.notna()]\n",
    "\n",
    "fp_data_uncorrected_with_gt_final = fp_data_uncorrected_with_gt_final.drop(columns=['iris_data', 'ms_library', 'isabel_data', 'sirius_data', 'old_klara_MMK', 'section_aces', 'section_kemikum','gc_probability'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657b31d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_data_uncorrected_with_gt_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c588d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save datframe\n",
    "# with open('/Users/elli/Library/CloudStorage/OneDrive-Kruvelab/Master_thesis/Data/MSMS/SIRIUS_output/output_no_mass_correction/2025-05-21_Rank1_fingerprints_with_ground_truth.pkl', 'wb') as f:\n",
    "#     pickle.dump(fp_data_uncorrected_with_gt, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584d30a6",
   "metadata": {},
   "source": [
    "# Prediction of top1 formula fingerprints with mass correction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95b88c7",
   "metadata": {},
   "source": [
    "## Get all fingerprints for top 1 molecular formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f5f30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ellinor = '/Users/elli/Library/CloudStorage/OneDrive-Kruvelab/Master_thesis/Data/MSMS/SIRIUS_output/output_mass_correction_2025-05-13/ellinor_data'\n",
    "iris = '/Users/elli/Library/CloudStorage/OneDrive-Kruvelab/Master_thesis/Data/MSMS/SIRIUS_output/output_mass_correction_2025-05-13/iris_data_dry'\n",
    "isabell = '/Users/elli/Library/CloudStorage/OneDrive-Kruvelab/Master_thesis/Data/MSMS/SIRIUS_output/output_mass_correction_2025-05-13/isabell_data'\n",
    "library = '/Users/elli/Library/CloudStorage/OneDrive-Kruvelab/Master_thesis/Data/MSMS/SIRIUS_output/output_mass_correction_2025-05-13/library_data'\n",
    "\n",
    "output_folders = [ellinor, iris, isabell, library]\n",
    "\n",
    "# get all MP\n",
    "fp_data_corrected, without_fp = get_rank1_fingerprints(output_folders, esi_mode='pos')\n",
    "fp_data_corrected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d1f7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_data_corrected.sort_values(by=['id'], inplace=True)\n",
    "fp_data_corrected=fp_data_corrected.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec077d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_data_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38154b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_results_corrected = fp_data_corrected[['id', 'formula', 'adduct']].copy()\n",
    "\n",
    "for model, name in zip(models, model_name): \n",
    "    if model == ahr_rf_model or model == ahr_xgb_model:\n",
    "        feature_names = ahr_features\n",
    "    else:\n",
    "        feature_names = mmp_features\n",
    "\n",
    "    # Make predictions\n",
    "    predicted_probabilities = make_predictions(fp_data_corrected.iloc[:, 3:], model, feature_names)\n",
    "    \n",
    "    # Add the predicted probabilities to the dataframe\n",
    "    predicted_results_corrected[name] = predicted_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd54db5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_results_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28358aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('2025-05-21_Model_evaluation_top1MF_pred_corrected_mass.pkl', 'wb') as f:\n",
    "#     pickle.dump(predicted_results_corrected, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f40f44b",
   "metadata": {},
   "source": [
    "## Connect to ground truth and get labels from tox21 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2894faff",
   "metadata": {},
   "source": [
    "### Clean fp_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff6b56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('2025-05-21_Model_evaluation_top1MF_pred_corrected_mass.pkl', 'rb') as f:\n",
    "    predicted_results_corrected = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df637719",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_results_corrected.id = predicted_results_corrected.id.apply(lambda x: x.translate(str.maketrans('', '', '()[]{}<>,.+ :\\'\\\"'))).str.lower()\n",
    "\n",
    "predicted_results_corrected.id = predicted_results_corrected.id.apply(lambda x: x.split('_'))\n",
    "\n",
    "predicted_results_corrected.id = ['_'.join(x[0:-1]) if x[-1]=='combined'\n",
    "                            else '_'.join(x) for x in predicted_results_corrected.id]\n",
    "\n",
    "predicted_results_corrected.id = predicted_results_corrected.id.apply(lambda x: x.split('-'))\n",
    "\n",
    "predicted_results_corrected.id = ['-'.join(x[0:-1]) if x[-1]=='e' or x[-1]=='h' or x[-1].isnumeric()\n",
    "                            else '-'.join(x) for x in predicted_results_corrected.id]\n",
    "\n",
    "predicted_results_corrected.id = predicted_results_corrected.id.apply(lambda x: x.translate(str.maketrans('', '', '_-')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e60d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_results_corrected.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06c7a54",
   "metadata": {},
   "source": [
    "### Merge with ground truth and tox21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9b9725",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_corrected_with_gt = tox21_gt.merge(predicted_results_corrected, on='id', how='left')\n",
    "\n",
    "fp_corrected_with_gt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f881485",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_corrected_with_gt = fp_corrected_with_gt.drop_duplicates(subset=fp_corrected_with_gt.columns, keep='first')\n",
    "fp_corrected_with_gt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97edde72",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_corrected_with_gt_final = fp_corrected_with_gt[fp_corrected_with_gt.formula.notna()]\n",
    "fp_corrected_with_gt_final = fp_corrected_with_gt_final.drop(columns=['iris_data', 'ms_library', 'isabel_data', 'sirius_data', 'old_klara_MMK', 'section_aces', 'section_kemikum','gc_probability'])\n",
    "fp_corrected_with_gt_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d17a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('evaluation_set_corrected_mass.pkl', 'wb') as f:\n",
    "#     pickle.dump(fp_corrected_with_gt_final, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beeda27e",
   "metadata": {},
   "source": [
    "# Evaluations and visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c46ad45",
   "metadata": {},
   "source": [
    "## Uncorrected evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44785e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, \\\n",
    "                            precision_recall_curve, roc_curve, balanced_accuracy_score, \\\n",
    "                            precision_score, f1_score, recall_score, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be99cc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('2025-05-18_threshold_fpr_at_90_recall_ahr_mmp_models.pkl', 'rb') as f:\n",
    "    model_metrics = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c637442",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_data_uncorrected_with_gt_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f590390f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_data_uncorrected_with_gt_final_ahr = fp_data_uncorrected_with_gt_final[fp_data_uncorrected_with_gt_final['nr.ahr'].notna()]\n",
    "fp_data_uncorrected_with_gt_final_mmp = fp_data_uncorrected_with_gt_final[fp_data_uncorrected_with_gt_final['sr.mmp'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39e1b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e0c396",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics.loc[0, 'threshold_90_recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67ace24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y_true, y_proba, threshold, model_name, endpoint):\n",
    "    # Calculate ROC-AUC score\n",
    "    roc_auc = roc_auc_score(y_true, y_proba)\n",
    "\n",
    "    # Calculate precision-recall curve\n",
    "    fpr, tpr, thresh= roc_curve(y_true, y_proba)\n",
    "    roc_auc_curve = pd.DataFrame({'fpr': fpr, \n",
    "                                  'tpr': tpr, \n",
    "                                  'thresh': thresh})\n",
    "\n",
    "    # Use threshold to get binary predictions\n",
    "    y_pred = np.where(y_proba >= threshold, 1, 0)\n",
    "\n",
    "    # Get confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "    # Calculate fpr_at_90_recall\n",
    "    fpr_90_recall = fp/(fp + tn)\n",
    "\n",
    "    # Calculate balanced accuracy\n",
    "    ba = balanced_accuracy_score(y_true, y_pred)\n",
    "\n",
    "    metrics_df = pd.DataFrame({'endpoint': [endpoint],\n",
    "                               'model': [model_name],\n",
    "                               'fpr_90_recall_evaluation': [fpr_90_recall],\n",
    "                               'roc_auc': [roc_auc],\n",
    "                               'balanced_accuracy': [ba]})\n",
    "    \n",
    "    #Make confusion matrix\n",
    "    cm_vis = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['Inactive', 'Active'])\n",
    "\n",
    "    \n",
    "    return metrics_df, roc_auc_curve, cm_vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ec706e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ahr_rf_metrics, ahr_rf_roc_auc_curve, ahr_rf_cm_vis = get_metrics(fp_data_uncorrected_with_gt_final_ahr['nr.ahr'],\n",
    "                                                                    fp_data_uncorrected_with_gt_final_ahr['ahr_rf_pred'],\n",
    "                                                                    model_metrics.loc[1, 'threshold_90_recall'],\n",
    "                                                                    'RF',\n",
    "                                                                    'AHR')\n",
    "ahr_xgb_metrics, ahr_xgb_roc_auc_curve, ahr_xgb_cm_vis = get_metrics(fp_data_uncorrected_with_gt_final_ahr['nr.ahr'],\n",
    "                                                                    fp_data_uncorrected_with_gt_final_ahr['ahr_xgb_pred'],\n",
    "                                                                    model_metrics.loc[0, 'threshold_90_recall'],\n",
    "                                                                    'XGB',\n",
    "                                                                    'AHR')\n",
    "mmp_rf_metrics, mmp_rf_roc_auc_curve, mmp_rf_cm_vis = get_metrics(fp_data_uncorrected_with_gt_final_mmp['sr.mmp'],\n",
    "                                                                    fp_data_uncorrected_with_gt_final_mmp['mmp_rf_pred'],\n",
    "                                                                    model_metrics.loc[2, 'threshold_90_recall'],\n",
    "                                                                    'RF',\n",
    "                                                                    'MMP')\n",
    "mmp_xgb_metrics, mmp_xgb_roc_auc_curve, mmp_xgb_cm_vis = get_metrics(fp_data_uncorrected_with_gt_final_mmp['sr.mmp'],\n",
    "                                                                    fp_data_uncorrected_with_gt_final_mmp['mmp_xgb_pred'],\n",
    "                                                                    model_metrics.loc[3, 'threshold_90_recall'],\n",
    "                                                                    'XGB',\n",
    "                                                                    'MMP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afe2e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "uncorrected_evaluation_metrics = pd.concat([ahr_rf_metrics, ahr_xgb_metrics, mmp_rf_metrics, mmp_xgb_metrics], ignore_index=True)\n",
    "uncorrected_evaluation_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21a198b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('2025-05-22_evaluation_metrics_uncorrected_mass.pkl', 'wb') as f:\n",
    "    pickle.dump(uncorrected_evaluation_metrics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929f55a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the figure parameters\n",
    "plt.rcParams.update({'figure.figsize':[9.8,9.8],\n",
    "                'font.size': 16, \n",
    "                'font.weight': 'normal',\n",
    "                'axes.titlesize': 12,\n",
    "                'axes.labelsize': 12,\n",
    "                'xtick.labelsize': 12,\n",
    "                'ytick.labelsize': 12,\n",
    "                'legend.fontsize': 12,\n",
    "                'legend.title_fontsize': 12,\n",
    "                'axes.titleweight': 'bold',\n",
    "                'font.family': 'serif',\n",
    "                'font.serif': ['Times New Roman'],\n",
    "                'figure.dpi':300,\n",
    "                \n",
    "                })\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(10, 9.5), dpi=300)\n",
    "# AHR\n",
    "ahr_rf_cm_vis.plot(ax=ax[0, 0], cmap='Blues', colorbar=False)\n",
    "ahr_rf_cm_vis.ax_.set_title('AhR RF')\n",
    "\n",
    "ahr_xgb_cm_vis.plot(ax=ax[0, 1], cmap='Blues', colorbar=False)\n",
    "ahr_xgb_cm_vis.ax_.set_title('AhR XGB')\n",
    "\n",
    "# MMP\n",
    "mmp_rf_cm_vis.plot(ax=ax[1, 0], cmap='Oranges', colorbar=False)\n",
    "mmp_rf_cm_vis.ax_.set_title('MMP RF')\n",
    "\n",
    "mmp_xgb_cm_vis.plot(ax=ax[1, 1], cmap='Oranges', colorbar=False)\n",
    "mmp_xgb_cm_vis.ax_.set_title('MMP XGB')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "#plt.suptitle('Evaluation set\\nConfusion matrices for AhR and MMP models at TPR=90%', fontsize=16, fontweight='bold', y=1.03)\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig('/Users/elli/Library/CloudStorage/OneDrive-Kruvelab/Master_thesis/Visualizations/2025-05-22_confusion_matrix_evaluation_uncorrected.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150e9f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot all ROC curves\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8, 5), dpi=300, tight_layout=True, sharex=True, sharey=True)\n",
    "\n",
    "ax[0].plot(ahr_rf_roc_auc_curve['fpr'], ahr_rf_roc_auc_curve['tpr'], label='AhR RF', color='#219EBC')\n",
    "ax[0].plot(ahr_xgb_roc_auc_curve['fpr'], ahr_xgb_roc_auc_curve['tpr'], label='AhR XGB', color='#023047')\n",
    "ax[0].grid(visible=True, which='both', linewidth=0.5, alpha=0.5)\n",
    "ax[0].set_title('AhR models')\n",
    "ax[0].legend(loc='lower right')\n",
    "ax[0].set_aspect('equal')\n",
    "\n",
    "\n",
    "ax[1].plot(mmp_rf_roc_auc_curve['fpr'], mmp_rf_roc_auc_curve['tpr'], label='MMP RF', color='#FFB703')\n",
    "ax[1].plot(mmp_xgb_roc_auc_curve['fpr'], mmp_xgb_roc_auc_curve['tpr'], label='MMP XGB', color='#FB8500')\n",
    "ax[1].grid(visible=True, which='both', linewidth=0.5, alpha=0.5)\n",
    "ax[1].set_title('MMP models')\n",
    "ax[1].legend(loc='lower right')\n",
    "ax[1].set_aspect('equal')\n",
    "\n",
    "\n",
    "#fig.suptitle('Evaluation set\\nROC-AUC for AhR and MMP models', fontweight='bold', fontsize=16, y = 0.93)\n",
    "fig.supxlabel('False Positive Rate', y=0.12, fontsize=12)\n",
    "fig.supylabel('True Positive Rate', x=0.05, fontsize=12)\n",
    "\n",
    "fig.savefig('/Users/elli/Library/CloudStorage/OneDrive-Kruvelab/Master_thesis/Visualizations/2025-05-22_roc_curves_ahr_mmp_evaluation_uncorrected.pdf', dpi=300, bbox_inches='tight',\n",
    "            transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f887815d",
   "metadata": {},
   "source": [
    "## Corrected evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50486b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_corrected_with_gt_final_ahr = fp_corrected_with_gt_final[fp_corrected_with_gt_final['nr.ahr'].notna()]\n",
    "fp_corrected_with_gt_final_mmp = fp_corrected_with_gt_final[fp_corrected_with_gt_final['sr.mmp'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aea43e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ahr_rf_metrics, ahr_rf_roc_auc_curve, ahr_rf_cm_vis = get_metrics(fp_corrected_with_gt_final_ahr['nr.ahr'],\n",
    "                                                                    fp_corrected_with_gt_final_ahr['ahr_rf_pred'],\n",
    "                                                                    model_metrics.loc[1, 'threshold_90_recall'],\n",
    "                                                                    'RF',\n",
    "                                                                    'AHR')\n",
    "ahr_xgb_metrics, ahr_xgb_roc_auc_curve, ahr_xgb_cm_vis = get_metrics(fp_corrected_with_gt_final_ahr['nr.ahr'],\n",
    "                                                                    fp_corrected_with_gt_final_ahr['ahr_xgb_pred'],\n",
    "                                                                    model_metrics.loc[0, 'threshold_90_recall'],\n",
    "                                                                    'XGB',\n",
    "                                                                    'AHR')\n",
    "mmp_rf_metrics, mmp_rf_roc_auc_curve, mmp_rf_cm_vis = get_metrics(fp_corrected_with_gt_final_mmp['sr.mmp'],\n",
    "                                                                    fp_corrected_with_gt_final_mmp['mmp_rf_pred'],\n",
    "                                                                    model_metrics.loc[2, 'threshold_90_recall'],\n",
    "                                                                    'RF',\n",
    "                                                                    'MMP')\n",
    "mmp_xgb_metrics, mmp_xgb_roc_auc_curve, mmp_xgb_cm_vis = get_metrics(fp_corrected_with_gt_final_mmp['sr.mmp'],\n",
    "                                                                    fp_corrected_with_gt_final_mmp['mmp_xgb_pred'],\n",
    "                                                                    model_metrics.loc[3, 'threshold_90_recall'],\n",
    "                                                                    'XGB',\n",
    "                                                                    'MMP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226f810d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_evaluation_metrics = pd.concat([ahr_rf_metrics, ahr_xgb_metrics, mmp_rf_metrics, mmp_xgb_metrics], ignore_index=True)\n",
    "corrected_evaluation_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de15b1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('2025-05-22_corrected_evaluation_metrics.pkl', 'wb') as f:\n",
    "    pickle.dump(corrected_evaluation_metrics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb9cb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the figure parameters\n",
    "plt.rcParams.update({'figure.figsize':[9.8,9.8],\n",
    "                'font.size': 16, \n",
    "                'font.weight': 'normal',\n",
    "                'axes.titlesize': 12,\n",
    "                'axes.labelsize': 12,\n",
    "                'xtick.labelsize': 12,\n",
    "                'ytick.labelsize': 12,\n",
    "                'legend.fontsize': 12,\n",
    "                'legend.title_fontsize': 12,\n",
    "                'axes.titleweight': 'bold',\n",
    "                'font.family': 'serif',\n",
    "                'font.serif': ['Times New Roman'],\n",
    "                'figure.dpi':300,\n",
    "                \n",
    "                })\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(10, 9.5), dpi=300)\n",
    "# AHR\n",
    "ahr_rf_cm_vis.plot(ax=ax[0, 0], cmap='Blues', colorbar=False)\n",
    "ahr_rf_cm_vis.ax_.set_title('AhR RF')\n",
    "\n",
    "ahr_xgb_cm_vis.plot(ax=ax[0, 1], cmap='Blues', colorbar=False)\n",
    "ahr_xgb_cm_vis.ax_.set_title('AhR XGB')\n",
    "\n",
    "# MMP\n",
    "mmp_rf_cm_vis.plot(ax=ax[1, 0], cmap='Oranges', colorbar=False)\n",
    "mmp_rf_cm_vis.ax_.set_title('MMP RF')\n",
    "\n",
    "mmp_xgb_cm_vis.plot(ax=ax[1, 1], cmap='Oranges', colorbar=False)\n",
    "mmp_xgb_cm_vis.ax_.set_title('MMP XGB')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "#plt.suptitle('Evaluation set\\nConfusion matrices for AhR and MMP models at TPR=90%', fontsize=16, fontweight='bold', y=1.03)\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig('/Users/elli/Library/CloudStorage/OneDrive-Kruvelab/Master_thesis/Visualizations/2025-05-22_confusion_matrix_evaluation_corrected.pdf', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db8f74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot all ROC curves\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8, 5), dpi=300, tight_layout=True, sharex=True, sharey=True)\n",
    "\n",
    "ax[0].plot(ahr_rf_roc_auc_curve['fpr'], ahr_rf_roc_auc_curve['tpr'], label='AhR RF', color='#219EBC')\n",
    "ax[0].plot(ahr_xgb_roc_auc_curve['fpr'], ahr_xgb_roc_auc_curve['tpr'], label='AhR XGB', color='#023047')\n",
    "ax[0].grid(visible=True, which='both', linewidth=0.5, alpha=0.5)\n",
    "ax[0].set_title('AhR models')\n",
    "ax[0].legend(loc='lower right')\n",
    "ax[0].set_aspect('equal')\n",
    "\n",
    "ax[1].plot(mmp_rf_roc_auc_curve['fpr'], mmp_rf_roc_auc_curve['tpr'], label='MMP RF', color='#FFB703')\n",
    "ax[1].plot(mmp_xgb_roc_auc_curve['fpr'], mmp_xgb_roc_auc_curve['tpr'], label='MMP XGB', color='#FB8500')\n",
    "ax[1].grid(visible=True, which='both', linewidth=0.5, alpha=0.5)\n",
    "ax[1].set_title('MMP models')\n",
    "ax[1].legend(loc='lower right')\n",
    "ax[1].set_aspect('equal')\n",
    "\n",
    "\n",
    "#fig.suptitle('Evaluation set\\nROC-AUC for AhR and MMP models', fontweight='bold', fontsize=16, y = 0.93)\n",
    "fig.supxlabel('False Positive Rate', y=0.12, fontsize=12)\n",
    "fig.supylabel('True Positive Rate', x=0.05, fontsize=12)\n",
    "\n",
    "fig.savefig('/Users/elli/Library/CloudStorage/OneDrive-Kruvelab/Master_thesis/Visualizations/2025-05-22_roc_curves_ahr_mmp_evaluation_corrected.pdf', dpi=300, bbox_inches='tight',\n",
    "           transparent=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pubchem_cleaning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
