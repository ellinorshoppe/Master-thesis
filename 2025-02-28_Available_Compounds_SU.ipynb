{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which active compounds are available in kemikum and ACES according to KLARA? **STAY TUNED AND FIND OUT!!!**\n",
    "\n",
    "### In this episode of **'We have no choice, experimental acquisition is needed'**, the sequel of **'APCI-HRMS data should be abundant, right?'**, we present the potential main characters of the test set! \n",
    "***PREVIOUSLY ON 'We have no choice, experimental acquisition is needed':*** \n",
    "\n",
    "All endpoints except AHR and MMP were voted out, since they had a larger number of polar compounds in their active/inactive split. Here we will found out which active compounds are available in KLARA Kemikum and ACES, and then an exiting hunt for the chemicals and the politics needed between the groups will determine which ones can be added to the final experimental dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **TASK 1: IS IT GC-AMENABLE?**\n",
    "Here we will make and look at histogram visualizations for both KLARA Kemikum and KLARA Aces datasets to determine if these compounds are predicted as GC-amenable compounds according to the SUSDAT dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#starting of strong by loading the data\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Made in '2025-01-30_Comparisons.ipynb'\n",
    "with open('/Users/elli/Library/CloudStorage/OneDrive-Kruvelab/Master_thesis/Code/Tox21 comparison/2025-03-06_tox21_ahr_mmp_available_compounds_all_sources_UPDATED.pkl', 'rb') as f:\n",
    "    tox21_ahr_mmp = pickle.load(f)\n",
    "\n",
    "\n",
    "sirius = pd.read_csv('/Users/elli/Library/CloudStorage/OneDrive-Kruvelab/Master_thesis/Data/SIRIUS training set/sirius_without_dup.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unique compounds with APCI spectra w. sirius data removed. \n",
    "\n",
    "# tox21 = tox21_ahr_mmp.drop_duplicates(subset=tox21_ahr_mmp.columns)\n",
    "# tox21 = tox21[tox21.sirius_data.isna()]\n",
    "\n",
    "# tox21 = tox21.dropna(subset=['ms_library', 'iris_data', 'isabel_data'], how='all')\n",
    "# tox21 = tox21.drop_duplicates(subset='InChIKey14')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering tox21 to only show actives\n",
    "tox21_actives = tox21_ahr_mmp[(tox21_ahr_mmp['nr.ahr'] == 1) | (tox21_ahr_mmp['sr.mmp'] == 1)].reset_index(drop=True)\n",
    "\n",
    "#Filtrate compounds to the gc-probability which is the highest of the multiple probabilities that are available, while still keeping information on locations\n",
    "tox21_actives_sorted = tox21_actives.sort_values(by=['InChIKey14', 'section_aces', 'section_kemikum', 'gc_probability'], ascending=[True, False, False, False]).reset_index(drop=True)\n",
    "tox21_actives_no_dup = tox21_actives_sorted.drop_duplicates(subset=['InChIKey14', 'section_aces', 'section_kemikum'], keep='first').reset_index(drop=True)\n",
    "\n",
    "#Remove any compounds already present in a ms library, iris data or isabel data\n",
    "tox21_experimental = tox21_actives_no_dup[(tox21_actives_no_dup['ms_library'].isna())&\n",
    "                                          (tox21_actives_no_dup['iris_data'].isna())&\n",
    "                                          (tox21_actives_no_dup['isabel_data'].isna())].reset_index(drop=True)\n",
    "\n",
    "#Filter so that all kemikum compounds are available in one dataset\n",
    "tox21_kemikum_actives = tox21_experimental.dropna(subset='section_kemikum').reset_index(drop=True)\n",
    "tox21_kemikum_actives_no_dupl = tox21_kemikum_actives.drop_duplicates(subset='InChIKey14', keep='first').reset_index(drop=True) \n",
    "\n",
    "#Filter so that all aces compounds are available in one dataset and remove any compounds which overlap with kemikum\n",
    "tox21_aces_actives = tox21_experimental.dropna(subset='section_aces').reset_index(drop=True)\n",
    "tox21_aces_actives = tox21_aces_actives[tox21_aces_actives.section_kemikum.isna()].reset_index(drop=True)\n",
    "tox21_aces_actives_no_dupl = tox21_aces_actives.drop_duplicates(subset='InChIKey14', keep='first').reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare the number of compounds in the different datasets\n",
    "tox21_kemikum_actives.shape, tox21_kemikum_actives_no_dupl.shape, tox21_aces_actives.shape, tox21_aces_actives_no_dupl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove any compounds that are already present in the SIRIUS training set\n",
    "tox21_kemikum_actives_no_dupl_no_sirius = tox21_kemikum_actives_no_dupl[tox21_kemikum_actives_no_dupl.sirius_data.isna()].reset_index(drop=True)\n",
    "tox21_aces_actives_no_dupl_no_sirius = tox21_aces_actives_no_dupl[tox21_aces_actives_no_dupl.sirius_data.isna()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the number of compounds in the different datasets after removing SIRIUS data\n",
    "tox21_kemikum_actives_no_dupl.shape, tox21_kemikum_actives_no_dupl_no_sirius.shape, tox21_aces_actives_no_dupl.shape, tox21_aces_actives_no_dupl_no_sirius.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tox21_kemikum_actives_no_dupl_no_sirius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any compounds that have a GC-probability of <0.5\n",
    "tox21_kemikum_actives_no_dupl_no_sirius_gc50 = tox21_kemikum_actives_no_dupl_no_sirius[tox21_kemikum_actives_no_dupl_no_sirius.gc_probability >= 0.5].reset_index(drop=True)\n",
    "tox21_aces_actives_no_dupl_no_sirius_gc50 = tox21_aces_actives_no_dupl_no_sirius[tox21_aces_actives_no_dupl_no_sirius.gc_probability >= 0.5].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tox21_kemikum_actives_no_dupl_no_sirius_gc50.shape, tox21_aces_actives_no_dupl_no_sirius_gc50.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tox21_kemikum_actives_no_dupl_no_sirius_gc50[tox21_kemikum_actives_no_dupl_no_sirius_gc50['sr.mmp']==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tox21_aces_actives_no_dupl_no_sirius_gc50[tox21_aces_actives_no_dupl_no_sirius_gc50['sr.mmp']==1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **SUBTASK 1: DATA VISUALIZATIONS**\n",
    "\n",
    "We will look at the GC-amenaibilty prediction for all available compounds for each section. From this we can then determine which percentage (or in this case; decimal point) will be an appropriate cutoff for subsetting appropriate compounds for the experimental analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_uni_tox21_expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_sirius_tox21_expr = tox21_experimental[tox21_experimental.sirius_data.isna()].reset_index(drop=True)\n",
    "at_uni_tox21_expr = no_sirius_tox21_expr[(no_sirius_tox21_expr.section_aces.notna())|(no_sirius_tox21_expr.section_kemikum.notna())]\n",
    "\n",
    "at_uni_tox21_expr = at_uni_tox21_expr.drop_duplicates(subset='InChIKey14', keep='first').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any duplicate chemicals from the datasets to make sure visualization is correct\n",
    "list_of_dfs = [tox21_kemikum_actives, tox21_kemikum_actives_no_sirius, tox21_aces_actives, tox21_aces_actives_no_sirius]\n",
    "list_of_dfs_for_visualization = []\n",
    "\n",
    "for df in list_of_dfs:\n",
    "    df = pd.DataFrame(df)\n",
    "    filtered_df = df.drop_duplicates(subset='InChIKey14', keep='first')\n",
    "    list_of_dfs_for_visualization.append(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the theme for the plots\n",
    "sns.set_theme(style='white', rc={'figure.figsize':(5,5), \n",
    "                                 'font.family':['Sans-serif'],\n",
    "                                 'font.sans-serif':['Times New Roman'], \n",
    "                                 'font.size':12, \n",
    "                                 'xtick.labelsize': 12,\n",
    "                                 'ytick.labelsize': 12,\n",
    "                                 'axes.labelsize': 12,\n",
    "                                 'axes.titlesize': 14,\n",
    "                                 'legend.fontsize': 12,\n",
    "                                 'legend.title_fontsize': 12,\n",
    "                                 'font.style': 'normal',\n",
    "                                 'font.weight': 400})\n",
    "                                \n",
    "                                \n",
    "\n",
    "plt.rcParams['savefig.transparent'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib.font_manager import FontProperties\n",
    "\n",
    "# Example datasets\n",
    "aces = tox21_aces_actives_no_dupl_no_sirius['gc_probability'] #aces data\n",
    "kemikum = tox21_kemikum_actives_no_dupl_no_sirius['gc_probability'] #kemikum data\n",
    "\n",
    "# Define bin edges\n",
    "bins = np.linspace(0, 1, 15)\n",
    "\n",
    "# Create stacked histogram\n",
    "plt.figure(figsize=(7, 3))\n",
    "plt.hist(at_uni_tox21_expr.gc_probability, bins=bins, color=['#58A7D2'], edgecolor=None)\n",
    "\n",
    "# Add labels and legend\n",
    "#bold_font = FontProperties(weight='bold')\n",
    "\n",
    "plt.xlabel('GC-probability')\n",
    "plt.ylabel('Compounds')\n",
    "#plt.title('Distribution of GC-probability for compounds\\navailable across departments', fontsize=14, fontweight='bold')\n",
    "#plt.legend(title='Departments', title_fontproperties=bold_font, loc='upper left')\n",
    "\n",
    "# Show the plot\n",
    "#plt.show()\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig('/Users/elli/Library/CloudStorage/OneDrive-Kruvelab/Master_thesis/Visualizations/2025-05-23_GC_probability_experimental.pdf', dpi=300, bbox_inches='tight', transparent=True)\n",
    "# plt.savefig('/Users/elli/Library/CloudStorage/OneDrive-Kruvelab/Ellinor - Master thesis/Visualizations/2025-03-06_Comparison_GC_probability.png', dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style='white', rc={'figure.figsize':(5,5), \n",
    "                                 'font.family':['Sans-serif'],\n",
    "                                 'font.sans-serif':['Times New Roman'], \n",
    "                                 'font.size':14, \n",
    "                                 'xtick.labelsize': 14,\n",
    "                                 'ytick.labelsize': 14,\n",
    "                                 'axes.labelsize': 14,\n",
    "                                 'axes.titlesize': 14,\n",
    "                                 'legend.fontsize': 14,\n",
    "                                 'legend.title_fontsize': 14,\n",
    "                                 'font.style': 'normal',\n",
    "                                 'font.weight': 400})\n",
    "                                \n",
    "                                \n",
    "\n",
    "plt.rcParams['savefig.transparent'] = True\n",
    "\n",
    "#First, let's look at the distribution of the number of compounds in the different data sources\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 6), sharey=True, sharex=True)\n",
    "\n",
    "#General information for figure\n",
    "fig.supxlabel('Probability of GC-amenability', fontweight='normal', color='black')\n",
    "fig.supylabel('Number of compounds', color='black')\n",
    "fig.suptitle('Distribution of the probability of \\nGC-amenability  for active compounds in KLARA', color='black', fontweight='bold')\n",
    "\n",
    "#Kemikum histograms\n",
    "axs[0].hist(list_of_dfs_for_visualization[0]['gc_probability'], bins=15, color='#8ECAE6', edgecolor='#023047', alpha= 0.5)\n",
    "axs[0].set_title('Kemikum\\nSIRIUS training data included')\n",
    "\n",
    "axs[0].hist(list_of_dfs_for_visualization[1]['gc_probability'], bins=15, color='#219EBC', edgecolor='#023047', alpha= 1)\n",
    "axs[0].set_title('Kemikum', color='#022E60')\n",
    "\n",
    "#ACES histograms\n",
    "axs[1].hist(list_of_dfs_for_visualization[2]['gc_probability'], bins=15, color='#FFB703', edgecolor='#023047', alpha = 0.5)\n",
    "axs[1].set_title('ACES\\nSIRIUS training data included')\n",
    "\n",
    "axs[1].hist(list_of_dfs_for_visualization[3]['gc_probability'], bins=15, color='#FB8500', edgecolor='#023047', alpha = 1)\n",
    "axs[1].set_title('ACES', color='#022E60')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#plt.savefig('2025-03-17_distr_gc_prob_KLARA.svg', format='svg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "rcParams.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And it is once again a beautiful visualization! We can clearly see from the this that most compounds are predicted to have either a very high or very low probability of GC-amenability for active compounds found in both Kemikum and ACES. We also see that the largest number of compounds are in general found in Kemikum and quite a bit fewer are found in ACES. Fortunately we don't seem to be loosing too many GC-amenable compounds when removing the SIRIUS training data. \n",
    "\n",
    "LETS FOUND OUT HOW MANY WE LOST! \n",
    "\n",
    "#### **SUBTASK 2: SPOT THE DIFFERENCE (SIRIUS training data edition)**\n",
    "\n",
    "With a probability of GC-amenability > 0.5, how many compounds did we loose for ACES and Kemikum respectively when removing SIRIUS training data? \n",
    "**FIND OUT AFTER THE BREAK!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANOTHER FUNCTION??!! This girl is on a roll today!\n",
    "def filter_gc_amenability(df, threshold):\n",
    "    \"\"\"\n",
    "    This function filters the data based on the probability of GC-amenability\n",
    "    \"\"\"\n",
    "\n",
    "    filtered_df = df[df['gc_probability'] > threshold].reset_index(drop=True)\n",
    "    return filtered_df\n",
    "\n",
    "#To make the application of the function as easy as possible, all df's are stored in a list and then looped over\n",
    "list_of_dfs_GC50 = []\n",
    "\n",
    "for df in list_of_dfs_for_visualization:\n",
    "    df_filtered = filter_gc_amenability(df, 0.5)\n",
    "    list_of_dfs_GC50.append(df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOW FOR THE RESULTS!!!\n",
    "\n",
    "#Kemikum compounds that are lost:\n",
    "kemikum_lost = len(list_of_dfs_GC50[0]) - len(list_of_dfs_GC50[1])\n",
    "print(f'Kemikum compounds lost: {kemikum_lost}\\n' +\n",
    "      f'Kemikum compounds left: {len(list_of_dfs_GC50[0])}')\n",
    "\n",
    "print('-----')\n",
    "#ACES compounds that are lost:\n",
    "aces_lost = len(list_of_dfs_GC50[2]) - len(list_of_dfs_GC50[3])\n",
    "print(f'ACES compounds lost: {aces_lost}\\n' +\n",
    "      f'ACES compounds left: {len(list_of_dfs_GC50[2])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**THE RESULTS ARE IN EVERYBODY!!!** \n",
    "\n",
    "In total we are loosing 93 and 20 compounds respectively from Kemikum and ACES when filtering out the SIRIUS training data. If all goes well that means that we have 187+46=***233 compounds to analyse!!!***\n",
    "\n",
    "Let us pray for the group politics going well so we manage to analyse all of them. \n",
    "\n",
    "But it's not over yet! Join us again after the break to find out what the other tasks will be!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\* break \\*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Welcome back!!***\n",
    "\n",
    "We're starting the second task of the evening;\n",
    "### TASK 2: 'Please Sir... Can I have 5mg, sir?'\n",
    "\n",
    "For this task we will compile lists to determine which compounds are found where, so that the supervisor, **the master herself** (!!!) can work her ***political magic*** to help us get the compounds needed for the experimental acquisition.\n",
    "\n",
    "We'll start the task off by cleaning the data for the task. \n",
    "\n",
    "#### SUBTASK 1: Clean the data again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tox21_experimental.drop_duplicates(subset='InChIKey14', keep='first').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tox21_experimental_GC50 = filter_gc_amenability(tox21_experimental, 0.5).reset_index(drop=True)\n",
    "\n",
    "tox21_experimental_GC50_no_sirius = tox21_experimental_GC50[tox21_experimental_GC50['sirius_data'].isna()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tox21_experimental_GC50.drop_duplicates(subset='InChIKey14', keep='first').reset_index(drop=True)\n",
    "\n",
    "tox21_experimental_GC50_no_sirius.drop_duplicates(subset='InChIKey14', keep='first').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compounds found in AC groups\n",
    "group_names_ac = ['Group Ulrika Nilsson', 'Kurslab_AK', 'Group Ioannis Sadiktsis', 'Group Jan Holmbäck','Masslab', 'Group Anneli Kruve', 'Group Nicole Pamme', 'Group Leopold Ilag']\n",
    "\n",
    "\n",
    "tox21_experimental_ac = tox21_experimental_GC50_no_sirius[tox21_experimental_GC50_no_sirius.section_kemikum.isin(group_names_ac)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kemikum (non-analytical) department unique compounds\n",
    "tox21_experimental_no_ac_compounds = tox21_experimental_GC50_no_sirius[~tox21_experimental_GC50_no_sirius.InChIKey14.isin(tox21_experimental_ac.InChIKey14)]\n",
    "tox21_experimental_mmk_org = tox21_experimental_no_ac_compounds.dropna(subset=['section_kemikum'], how='all').reset_index(drop=True)\n",
    "\n",
    "#aces unique compounds\n",
    "tox21_experimental_aces = tox21_experimental_no_ac_compounds[~tox21_experimental_no_ac_compounds.InChIKey14.isin(tox21_experimental_ac.InChIKey14)].reset_index(drop=True)\n",
    "tox21_experimental_aces = tox21_experimental_aces[~tox21_experimental_aces.InChIKey14.isin(tox21_experimental_mmk_org.InChIKey14)].reset_index(drop=True)\n",
    "tox21_experimental_aces = tox21_experimental_aces.dropna(subset=['section_aces'], how='all').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SUBTASK 2: Determine active/inactive count of endpoints for compounds\n",
    "\n",
    "Remember that all compounds are active in at least one of the two endpoints, so a higher ratio of actives to inactives is normal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def active_inactive_count(df, endpoints_list):\n",
    "    df = df.drop_duplicates(subset='InChIKey14')\n",
    "    for endpoint in endpoints_list:\n",
    "        print(f'Active/inactive count for {endpoint}')\n",
    "        print(df.value_counts(endpoint))\n",
    "\n",
    "endpoints_list = ['nr.ahr', 'sr.mmp']\n",
    "\n",
    "print('Analytical department')\n",
    "active_inactive_count(tox21_experimental_ac, endpoints_list)\n",
    "print('------')\n",
    "\n",
    "print('Other departments')\n",
    "active_inactive_count(tox21_experimental_mmk_org, endpoints_list)\n",
    "print('------')\n",
    "\n",
    "print('ACES')\n",
    "active_inactive_count(tox21_experimental_aces, endpoints_list)\n",
    "print('------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SUBTASK 3: Combine cleaned data with KLARA information\n",
    "\n",
    "By first opening the two KLARA datasets (ACES and Kemikum) we can then rename the column for section to fit the version described in the tox21 version. We will then append these columns to the KLARA data. \n",
    "\n",
    "Following main tasks: \n",
    "1. Open KLARA datasets\n",
    "2. Rename 'section' column to 'section_{name of KLARA dataset}'\n",
    "3. Drop any rows which doesn't have any InChIKey14 in column of same name\n",
    "4. Drop any rows which has complete copies over all columns, only keep the first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open klara data for kemikum and aces\n",
    "\n",
    "with open('/Users/elli/Library/CloudStorage/OneDrive-Kruvelab/Ellinor - Master thesis/Code/Data cleaning/2025-02-13_klara_aces_cleaned.pkl', 'rb') as f:\n",
    "    klara_aces = pickle.load(f)\n",
    "\n",
    "klara_aces.rename(columns={'section': 'section_aces'}, inplace=True)\n",
    "\n",
    "with open('/Users/elli/Library/CloudStorage/OneDrive-Kruvelab/Ellinor - Master thesis/Code/Data cleaning/2025-03-06_klara_kemikum_UPDATED_cleaned.pkl', 'rb') as f:\n",
    "    klara_kemikum = pickle.load(f)\n",
    "\n",
    "klara_kemikum.rename(columns={'section': 'section_kemikum'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_klara_data(df):\n",
    "    \"\"\"\n",
    "    This function filters the data to only include compounds which have InChIKey14's and their various locations information, any duplicate information is removed\n",
    "    \"\"\"\n",
    "    new_df = df.dropna(subset='InChIKey14', how='all').reset_index(drop=True)\n",
    "    new_df = new_df.drop_duplicates(subset=new_df.columns, keep='first').reset_index(drop=True)\n",
    "\n",
    "    return new_df\n",
    "\n",
    "klara_aces_unique = filter_klara_data(klara_aces)\n",
    "klara_kemikum_unique = filter_klara_data(klara_kemikum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_klara_data(df, klara_data, section_name):\n",
    "    \"\"\"\n",
    "    This function adds the klara data to the df, and then filter out any duplicate rows\n",
    "    \"\"\"\n",
    "    new_df = klara_data.merge(df[['gc_probability', 'nr.ahr', 'sr.mmp', 'InChIKey14', section_name]], on=['InChIKey14', section_name], how='inner')\n",
    "    new_df = new_df.drop_duplicates(subset=new_df.columns, keep='first').reset_index(drop=True)\n",
    "\n",
    "    new_df = new_df.rename(columns={section_name: 'section'})\n",
    "\n",
    "    return new_df\n",
    "\n",
    "klara_ac_chemicals = add_klara_data(tox21_experimental_ac, klara_kemikum_unique, 'section_kemikum')\n",
    "klara_mmk_org_chemicals = add_klara_data(tox21_experimental_mmk_org, klara_kemikum_unique, 'section_kemikum')\n",
    "klara_aces_chemicals = add_klara_data(tox21_experimental_aces, klara_aces_unique, 'section_aces')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SUBTASK 4: Compiling lists of actives to ask and analyse\n",
    "\n",
    "Which compounds are already available in the group to analyse? Which are available in the corridor to ask about? \n",
    "\n",
    "Let's continue to find out!!\n",
    "\n",
    "##### Analytical Chemistry section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compounds to be removed from AC chemicals list\n",
    "\n",
    "filter_ac_compounds_to_remove = ['2,4-toluendiisocyanat (isomerblandning) ' #Not apporopriate for MS analysis to work with isomer mix \n",
    "                                 ]\n",
    "\n",
    "klara_ac_chemicals = klara_ac_chemicals[~klara_ac_chemicals['name'].isin(filter_ac_compounds_to_remove)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klara_ac_chemicals.section.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_groups(df, group_names):\n",
    "\n",
    "    '''\n",
    "    Separate the chemicals into different groups based on the group names provided, \n",
    "    returns a dictionary with group name as key, and the chemical-df as value\n",
    "    '''\n",
    "\n",
    "    new_df = df\n",
    "    groups_dict = {}\n",
    "\n",
    "    for group_name in group_names:\n",
    "        group = new_df[(new_df['section'].str.contains(group_name))].reset_index(drop=True)\n",
    "        new_df = new_df[~new_df['InChIKey14'].isin(group['InChIKey14'])]\n",
    "\n",
    "        group_sorted = group.sort_values(by=['InChIKey14', 'cas', 'amount'], ascending=[True,True,False])\n",
    "        group_filtered = group_sorted.drop_duplicates(subset=['InChIKey14', 'cas'], keep='first').reset_index(drop=True)\n",
    "\n",
    "        groups_dict[str(group_name)] = group_filtered\n",
    "\n",
    "\n",
    "    return new_df, groups_dict\n",
    "\n",
    "\n",
    "ac_group_names = ['Group Anneli Kruve', 'Group Ulrika Nilsson', 'Group Ioannis Sadiktsis', 'Kurslab_AK', 'Masslab', 'Group Leopold Ilag', 'Group Nicole Pamme','Group Jan Holmbäck'] #To assure hirarchy of groups to ask is preserved\n",
    "klara_ac_chemicals_updated, klara_ac_separate_groups_dict = separate_groups(klara_ac_chemicals, ac_group_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klara_ac_separate_groups_dict.keys() #Check that all groups are included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klara_ac_chemicals_final = pd.concat(klara_ac_separate_groups_dict.values(), ignore_index=True)\n",
    "\n",
    "klara_ac_chemicals_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the grouping above we see a natural hirarchy forming, the groups which have highest prority or chance of getting compounds are higher up in the list. Compounds are then continually removed if they are transfered to their own grouping so no compound is found in different groups. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klara_ac_chemicals_updated.shape #Should show no entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MMK/Org sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klara_mmk_org_chemicals.section.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmk_org_group_names = ['Group Joseph Samec', 'Group Kálmán J Szabó', 'Group Miguel Rivero Crespo', 'Group Pher Andersson', 'Group Erica Zeglio', 'Group Belén Martín-Matute', \n",
    "                       'Group Berit Olofsson', 'Grupp Jiayin Yuan', 'Group Xiaodong Zou', 'Group Biswanath Das' , 'Group Jan E Bäckvall', 'Kemiska övningslaboratoriet, KÖL (MMK)']\n",
    "\n",
    "klara_mmk_org_chemicals_updated, klara_mmk_org_separate_groups_dict = separate_groups(klara_mmk_org_chemicals, mmk_org_group_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ACES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klara_aces_chemicals_active = klara_aces_chemicals[(klara_aces_chemicals['nr.ahr'] == 1)|(klara_aces_chemicals['sr.mmp'] == 1) ].reset_index(drop=True)\n",
    "klara_aces_chemicals_active = klara_aces_chemicals_active[klara_aces_chemicals_active['section']=='ACESo, Contaminant Chemistry Unit'].reset_index(drop=True)\n",
    "\n",
    "klara_aces_chemicals_active = klara_aces_chemicals_active.drop_duplicates(subset=['name', 'cas', 'amount', 'unit', 'building', 'floor', 'room', 'storage', 'section'], keep='first').reset_index(drop=True)\n",
    "klara_aces_chemicals_active = klara_aces_chemicals_active.sort_values(by='name', ascending=True)\n",
    "klara_aces_chemicals_active = klara_aces_chemicals_active.drop(index=[60, 33, 48, 39, 40, 53, 27, 42, 45, 36])\n",
    "\n",
    "klara_aces_chemicals_active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cedrol_index = klara_aces_chemicals_active[klara_aces_chemicals_active.name=='[3R-(3alpha,3aBeta,6alpha,7beta,8aAlpha)]-'].index\n",
    "\n",
    "klara_aces_chemicals_active.loc[cedrol_index, 'name'] = 'Cedrol'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compounds_to_remove = ['Chlordane (mixture of isomers)', #Not appropriate for MS analysis to work with isomer mix\n",
    "                       '4-Dodecylphenol, mixture of isomers' #Not appropriate for MS analysis to work with isomer mix\n",
    "                       ] \n",
    "\n",
    "klara_aces_chemicals_active = klara_aces_chemicals_active[~klara_aces_chemicals_active['name'].isin(compounds_to_remove)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klara_aces_chemicals_final = klara_aces_chemicals_active.drop_duplicates(subset=['name', 'cas', 'InChIKey'], keep='first').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klara_aces_chemicals_active_location = klara_aces_chemicals_active[['name', 'cas', 'barcode', 'amount', 'unit', 'building', 'floor', 'room', 'storage', 'section', 'comment']].reset_index(drop=True)\n",
    "\n",
    "klara_aces_chemicals_active_location\n",
    "\n",
    "klara_aces_chemicals_active_location.to_excel('2025-04-08_KLARA_ACES_chemicals_to_borrow_location.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK 3: List compilation of all compounds which are available\n",
    "##### Groups which has graciously allowed for us to use their chemicals\n",
    "\n",
    "**Cheers to the groups which has allowed for us to use their chemcials**\n",
    "\n",
    "Groups that have have allowed for us to use their chemicals (will be updated):\n",
    "\n",
    "From AC:\n",
    "- Group Kruve\n",
    "- Group Nilsson\n",
    "- Group Sadiktsis\n",
    "- Course lab \n",
    "- Group Ilag\n",
    "\n",
    "From MMK/Org:\n",
    "- Group Szabó (Group KS)\n",
    "- Group Samec (Group JoS)\n",
    "- Group Crespo\n",
    "- Group Andersson\n",
    "- Group Zeglio\n",
    "- Group Martín-Matute\n",
    "- Group Olofsson\n",
    "- Group Yuan\n",
    "- Group Zou\n",
    "- Group Das\n",
    "- Group Bäckvall\n",
    "\n",
    "From ACES:\n",
    "- ACESo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klara_mmk_org_chemicals_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# klara_mmk_org_chemicals_to_send_to_anneli = klara_mmk_org_chemicals_updated[['name', 'cas', 'section', 'nr.ahr', 'sr.mmp']]\n",
    "\n",
    "# klara_mmk_org_chemicals_to_send_to_anneli.to_excel('2025-03-07_updated_kemikum_chemicals.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each group, save the chemicals to a separate csv file\n",
    "for key in klara_mmk_org_separate_groups_dict.keys():\n",
    "    df = klara_mmk_org_separate_groups_dict[key]\n",
    "    df = df[['name', 'cas','amount', 'unit', 'room', 'storage', 'comment']]\n",
    "    df.to_csv(f'2025-03-26_chemicals_to_borrow_{key}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klara_mmk_org_chemicals_final = pd.concat(klara_mmk_org_separate_groups_dict.values(), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klara_mmk_org_chemicals_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add all the available actives to one dataframe\n",
    "all_available_actives = pd.concat([klara_ac_chemicals_final, klara_mmk_org_chemicals_final, klara_aces_chemicals_final]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reorganize the columns to make it easier to read\n",
    "all_available_actives = all_available_actives[['name', 'cas', 'section', 'nr.ahr', 'sr.mmp', \n",
    "                                               'amount', 'unit', 'building', 'floor', 'room', 'storage',\n",
    "                                               'comment', 'barcode', 'SMILES', 'ROMol', 'split_SMILES', 'InChIKey', 'InChIKey14',\n",
    "                                               'duplicate_InChIKey', 'gc_probability']]\n",
    "\n",
    "all_available_actives.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/elli/Library/CloudStorage/OneDrive-Kruvelab/Ellinor - Master thesis/Code/Experimental_work/2025-04-15_klara_available_actives.pkl', 'wb') as f:\n",
    "    pickle.dump(all_available_actives, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "with open('/Users/elli/Library/CloudStorage/OneDrive-Kruvelab/Ellinor - Master thesis/Experimental/Experimental_work/2025-04-03_klara_available_actives.pkl', 'rb') as f:\n",
    "    all_available_actives = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_available_actives[all_available_actives['nr.ahr']==1]['nr.ahr'].sum())\n",
    "print(all_available_actives[all_available_actives['sr.mmp']==1]['sr.mmp'].sum())\n",
    "print(all_available_actives[(all_available_actives['nr.ahr']==1)&(all_available_actives['sr.mmp']==1)].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the making of the standards some thing may have happened leading to some compounds not going all the way to analysis. \n",
    "\n",
    "These will be removed using a filter which consists of all compound which had various issues throughout the standard making process, as well as a comment next to the name as to why. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compounds_to_remove = ['Toluylene diisocyanate (mixutre of isomeres) <br>(mass)', # not appropriate for MS analysis, was also prone to polymerization\n",
    "                       \"N,N'-Dicyklohexylkarbodiimid\", # Reacts with water, determined to not be appropriate to work with\n",
    "                       'Folpet',#Not found\n",
    "                       '1,2,5,6,9,10-Hexabromocyclododecane', #Not found\n",
    "                       '4-Phenoxyphenol', #Not found\n",
    "                       'Lindane', #Not found\n",
    "                       '4-(Methylamino)phenol hemisulfate salt', #Not found\n",
    "                       'p-Toluidin', #Too crystalized in packaging, could not be transferred\n",
    "                       'Aminoguanidine bicarbonate',# Could not be dissolved in anything other that water  \n",
    "                       '1,2,4-Triazole', #Not found\n",
    "                       '1,2,4-Triazole sodium derivative', #Not found\n",
    "                       'beta-Phenylcinnamaldehyde', #Not found\n",
    "                       'Triton X-100 (Sigma-Aldrich Sweden AB)' #Determined to not be suitable for GC-analysis\n",
    "                       ] \n",
    "\n",
    "all_available_actives_updated = all_available_actives[~all_available_actives['name'].isin(compounds_to_remove)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import PandasTools, Descriptors, rdMolDescriptors, Crippen, Fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_molecular_formula_and_mol_weight(df):\n",
    "    '''\n",
    "    This function calculates the following chemical characteristics:\n",
    "         molecular formula\n",
    "         monoisotopic molecular weight\n",
    "         LogP\n",
    "         number of amines\n",
    "         number of hydroxyls\n",
    "         number of hydrogen bond acceptors\n",
    "         number of hydrogen bond donors\n",
    "    '''\n",
    "\n",
    "    PandasTools.AddMoleculeColumnToFrame(df, smilesCol='SMILES')\n",
    "    df['monoisotopic_molecular_weight'] = df['ROMol'].apply(Chem.rdMolDescriptors.CalcExactMolWt)\n",
    "    df['molecular_formula'] = df['ROMol'].apply(Chem.rdMolDescriptors.CalcMolFormula)\n",
    "    df['logP'] = df['ROMol'].apply(Chem.Crippen.MolLogP)\n",
    "\n",
    "    prim_amines = df['ROMol'].apply(Chem.Fragments.fr_NH2)\n",
    "    sec_amines = df['ROMol'].apply(Chem.Fragments.fr_NH1)\n",
    "    tert_amines = df['ROMol'].apply(Chem.Fragments.fr_NH0)\n",
    "    arom_amines = df['ROMol'].apply(Chem.Fragments.fr_Ar_NH)\n",
    "    df['amines'] = prim_amines + sec_amines + tert_amines + arom_amines\n",
    "\n",
    "    aliph_hydroxyls = df['ROMol'].apply(Chem.Fragments.fr_Al_OH)\n",
    "    aromatic_hydroxyls = df['ROMol'].apply(Chem.Fragments.fr_Ar_OH)\n",
    "    df['hydroxyls'] = aliph_hydroxyls + aromatic_hydroxyls\n",
    "\n",
    "    df['HBA'] = df['ROMol'].apply(Chem.rdMolDescriptors.CalcNumLipinskiHBA)\n",
    "    df['HBD'] = df['ROMol'].apply(Chem.rdMolDescriptors.CalcNumLipinskiHBD)\n",
    "    return df\n",
    "\n",
    "all_available_actives_updated = calc_molecular_formula_and_mol_weight(all_available_actives_updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get pubhcem CID to be able to get the PubChem data\n",
    "import pubchempy as pcp\n",
    "\n",
    "def get_pubchem_cid(df):\n",
    "    '''\n",
    "    This function gets the PubChem cid for the compounds in the dataframe\n",
    "    '''\n",
    "    pubchem_data = []\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            compound = pcp.get_compounds(row['InChIKey'], 'inchikey')[0].to_dict(properties=['cid'])['cid']\n",
    "            pubchem_data.append(compound)\n",
    "        except:\n",
    "            print('Failed to get data for compound:', row['InChIKey'])\n",
    "            pubchem_data.append(None)\n",
    "\n",
    "    df['pubchem_cid'] = pubchem_data\n",
    "    return df\n",
    "\n",
    "all_available_actives_updated = get_pubchem_cid(all_available_actives_updated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "#get spectral and experimental data from PubChem\n",
    "def get_pubchem_data(cid):\n",
    "    '''\n",
    "    Get information on spectral data from PubChem\n",
    "    '''\n",
    "\n",
    "    def get_spectral_data(cid):\n",
    "        '''\n",
    "        Get information on spectral data from PubChem\n",
    "        '''\n",
    "        # Get the PubChem CID for the compound\n",
    "        gcms = False\n",
    "        lcms = False\n",
    "        \n",
    "        for subsection in section:\n",
    "            if subsection.get('TOCHeading') == 'Spectral Information':\n",
    "                spectral_info = subsection.get('Section')\n",
    "                for subsection in spectral_info:\n",
    "                    if subsection.get('TOCHeading') == 'Mass Spectrometry':\n",
    "                        mass_spec = subsection.get('Section')\n",
    "                        for subsection in mass_spec:\n",
    "                            if subsection.get('TOCHeading') == 'GC-MS':\n",
    "                                gcms = True\n",
    "                            elif subsection.get('TOCHeading') == 'LC-MS':\n",
    "                                lcms = True \n",
    "\n",
    "        return gcms, lcms\n",
    "    \n",
    "    def get_experimental_data(cid):\n",
    "        '''\n",
    "        Get experimental data from PubChem\n",
    "        '''\n",
    "        # Get the PubChem CID for the compound\n",
    "        bp = []\n",
    "        vp = []\n",
    "        for subsection in section:\n",
    "            if subsection.get('TOCHeading') == 'Chemical and Physical Properties':\n",
    "                chemical_props = subsection.get('Section')\n",
    "\n",
    "                for subsection in chemical_props:\n",
    "                    if subsection.get('TOCHeading') == 'Experimental Properties':\n",
    "                        experimental_props = subsection.get('Section')\n",
    "                        \n",
    "                        for subsection in experimental_props:\n",
    "                            if subsection.get('TOCHeading') == 'Boiling Point':\n",
    "                                # Extract boiling point\n",
    "                                bp_info = subsection.get('Information')\n",
    "                                for ref in bp_info:\n",
    "                                    if any('ExtendedReference' in k for k in ref):\n",
    "                                        if any('Matched' in k for k in ref.get('ExtendedReference')[0]): # Requires Matching to library to be true\n",
    "                                            bp.append(str(ref.get('Value').get('StringWithMarkup')[0].get('String')))\n",
    "                                        \n",
    "                            elif subsection.get('TOCHeading') == 'Vapor Pressure':\n",
    "                                # Extract vapor pressure\n",
    "                                vp_info = subsection.get('Information')\n",
    "                                for ref in vp_info:\n",
    "                                    if any('ExtendedReference' in k for k in ref):\n",
    "                                        if any('Matched' in k for k in ref.get('ExtendedReference')[0]):\n",
    "                                            vp.append(str(ref.get('Value').get('StringWithMarkup')[0].get('String')))\n",
    "                            \n",
    "        return bp, vp\n",
    "        \n",
    "\n",
    "    url = f\"https://pubchem.ncbi.nlm.nih.gov/rest/pug_view/data/compound/{cid}/JSON\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url).json()\n",
    "\n",
    "        section = response.get('Record').get('Section')\n",
    "\n",
    "        # Check if the JSON contains spectral information\n",
    "        gcms, lcms = get_spectral_data(section)\n",
    "        # Check if the JSON contains experimental data\n",
    "        bp, vp = get_experimental_data(section)\n",
    "\n",
    "        return gcms, lcms, bp, vp\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for CID {cid}: {e}\")\n",
    "        return np.nan, np.nan, np.nan, np.nan\n",
    "\n",
    "# Get the PubChem data for all available actives\n",
    "all_available_actives_updated[['gcms_spectra_available', 'lcms_spectra_available', 'boiling_point', 'vapor_pressure']] = all_available_actives_updated['pubchem_cid'].apply(get_pubchem_data).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_available_actives_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_available_actives_updated.to_csv('2025-04-07_Ellinors_compounds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_actives_w_same_mol_formula = all_available_actives[all_available_actives.duplicated(subset='molecular_formula', keep=False)].reset_index(drop=True).sort_values(by='molecular_formula')\n",
    "\n",
    "available_actives_w_same_mol_formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = all_available_actives_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.index = test.cas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_available_actives_updated.monoisotopic_molecular_weight.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_available_actives_updated.to_csv('2025-03-26_endocrine_tox_active_chemicals.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_available_actives_updated.ROMol[37]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each mix, a list of the compound names available on klara is made. These are then used to filter out the already used compounds from the 'all_available_actives' df, while making a new df for each mix, for easy acess to the information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix1_list = ['4-Chlorophenyl isocyanate', '2-Chloroacetophenone', 'alpha-Tetralone (volume)', 'cis-Stilbene (mass)', 'Triphenylborane', 'Indene (mass)', 'Ftaldialdehyd ', 'p-Chloranil']\n",
    "\n",
    "mix2_list = ['N-Phenyl-o-phenylenediamine', '3-(Dimethylamino)-phenol', 'N,N-Dimethyl-p-phenylenediamine', '2-Nitrophenylacetonitrile', '1,3-Phenylenediamine', 'Benzhydrazide', '2,4,6-Trichlorophenol', 'N,N-Dimethyl-p-toluidine (mass)',\n",
    "             '2,3-Diaminotoluene', '1-Naphthol', 'Thiourea', 'Myristyltrimethylammonium bromide', 'Hexadecyltrimetylammoniumbromid', 'N,N-Diethyl-1,4-phenylenediammonium sulfate']\n",
    "\n",
    "mix3_list = ['Tetramethylthiuram disulfide', 'Parathion-methyl', '5-Nitroacenaphthene', '2-Nitrofluorene', '6-Nitroquinoline', '1-Nitronaphthalene', 'Quinoline Yellow', \n",
    "             'N-Cyclohexylbenzothiazole-2-sulphenamide', 'N-tert-Butyl-2-benzothiazolesulfenamide', '4-Chloro-m-phenylenediamine']\n",
    "\n",
    "mix4_list = ['9,10-Dihydrobenzo[a]pyrene-7(8H)-one', '8-Nitroquinoline', '1,2:3,4-Dibenzanthracene','3-Aminofluoranthene',  '1-Methylpyrene',\n",
    "             '9-Anthracenemethanol', 'Anthrone', '2-Amino-4-methylphenol']\n",
    "\n",
    "mix5_list = ['2-Methylanthraquinone', 'p-Anisidine (Sigma-Aldrich 800458)', 'N,N-Dimethyl-4-nitrosoaniline', '1-(2-Chlorophenyl)-1-(4-chlorophenyl)-2,2-<br>dichloroethane',\n",
    "             \"4,4'-Dihydroxybiphenyl\" ]\n",
    "\n",
    "mixes_list = [mix1_list, mix2_list, mix3_list, mix4_list, mix5_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(mixes_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixes_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix1_df = all_available_actives_updated[all_available_actives_updated.name.isin(mixes_list[0])]\n",
    "mix1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_mixes(df, mix_list):\n",
    "\n",
    "    '''\n",
    "    Separate the chemicals into different groups based on the group names provided, \n",
    "    returns a dictionary with group name as key, and the chemical-df as value\n",
    "    '''\n",
    "\n",
    "    new_df = df\n",
    "    mixes_dict = {}\n",
    "    nr = 1\n",
    "\n",
    "    for mix_nr in mix_list:\n",
    "        mix_df = new_df[new_df['name'].isin(mix_nr)].reset_index(drop=True)\n",
    "        new_df = new_df[~new_df['name'].isin(mix_nr)].reset_index(drop=True)\n",
    "        \n",
    "        mix_df = mix_df.sort_values(by='monoisotopic_molecular_weight', ascending=True)\n",
    "\n",
    "        mixes_dict['mix'+str(nr)] = mix_df\n",
    "        nr += 1\n",
    "\n",
    "\n",
    "    return new_df, mixes_dict\n",
    "\n",
    "all_available_actives_updated2, active_mixes_dict = separate_mixes(all_available_actives_updated, mixes_list)\n",
    "active_mixes_dict.keys() #Check that all mixes are included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_mixes_dict['mix1']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pubchem_cleaning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
